{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>This documentation is under development, as is the project it concerns. Some elements may be missing, superfluous, need to be modified or clarified.  </p> <p>In the event of problems or requests,  it is possible to open an issue </p>"},{"location":"#design","title":"Design","text":"<p>The aim of this project, centered on the znuny application, is to provide a reliable,  high-performance container image for quick and easy production release. </p> <p>This image and the various deployment methods provided in the repository are specifically  designed to be hosted on a Kubernetes platform.</p> <p>The various functionalities are designed for production use with a multitude of deployed instances.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Local users configuration</li> <li>Support for multiple databases<ul> <li>MariaDB</li> <li>PostgreSQL</li> </ul> </li> <li>Mailing configuration</li> <li>Ldap authentication configuration<ul> <li>Ldap agents authentication</li> <li>Ldap consumer authentication</li> </ul> </li> <li>Log outputs formatted in JSON and configurable between rsyslog and file outputs</li> <li>Configuration of Apache rewrite rules</li> </ul>"},{"location":"helm/deployment/","title":"Deployment","text":""},{"location":"helm/deployment/#configurations","title":"Configurations","text":"<p>By default, Helm deployment is configured via a value file. This file can be found in the Github repository.</p>"},{"location":"helm/deployment/#helm-release-configurations","title":"Helm release configurations","text":"Option Default Description nameOverride {} Overrides the release name namespaceOverride {} Overrides the namespace name"},{"location":"helm/deployment/#serviceaccount-configurations","title":"ServiceAccount configurations","text":"Option Default Description serviceAccount.create true Defines whether the ServiceAccount should be created or not serviceAccount.annotations {} Defines ServiceAccount annotations serviceAccount.name \"\" Defines the name of the ServiceAccount"},{"location":"helm/deployment/#pod-strategies-configurations","title":"Pod strategies configurations","text":"Option Default Description imagePullSecrets [] Defines the secrets to be used to pull the image restartPolicy Always Defines the restart policy deploymentStrategy Recreate Defines the deployment behavour replicaCount 1 Define the desired number of replicas"},{"location":"helm/deployment/#image-configurations","title":"Image configurations","text":"Option Default Description image.repository ghcr.io/mln-nicolas-b/docker-znuny Defines the name of the image to be used image.tag v6.5.3-1 Defines the tag of the image to be used image.pullPolicy IfNotPresent Defines the pull policy of the image"},{"location":"helm/deployment/#logs-configurations","title":"Logs configurations","text":"Option Default Description config.logs {} Defines whether the Znuny application should log to a file and provides the file path."},{"location":"helm/deployment/#external-database-configurations","title":"External database configurations","text":"Option Default Description config.database.type mysql Defines the type of the external database config.database.host host Defines the host of the external database config.database.port port Defines the port of the external database config.database.name name Defines the name of the external database config.database.user user Defines the connection user of the external database config.database.password password Defines the connection password of the external database"},{"location":"helm/deployment/#web-server-configurations","title":"Web server configurations","text":"Option Default Description config.apache.domain znuny.domain.tld Defines a ServerName in the virtualhost of the Apache2 server config.apache.rewriteRules {} Defines request rewriting rules in the Apache2 server virtualhost"},{"location":"helm/deployment/#local-users-configurations","title":"Local users configurations","text":"Option Default Description config.users.admin.name root@localhost Defines the username of the local administrator user config.users.admin.password password Defines the password of the local administrator user"},{"location":"helm/deployment/#mailing-configurations","title":"Mailing configurations","text":"Option Default Description config.mails.type external Defines the method used to send e-mails config.mails.host smtp.domain.tld Defines the SMTP server host config.mails.port 25 Defines the SMTP server port config.mails.user znuny@domain.tld Defines the SMTP server user name config.mails.password none Defines the SMTP server user password"},{"location":"helm/deployment/#authentications-backends-configurations","title":"Authentications backends configurations","text":"Option Default Description config.authentications.customers.backends {} Define an authentication backend for customer login config.authentications.customers.synchronizations {} Defines a synchronization backend for local client storage config.authentications.agents.backends {} Define an authentication backend for agent login config.authentications.agents.synchronizations {} Defines a synchronization backend for local client storage"},{"location":"helm/deployment/#autoscaling-configurations","title":"Autoscaling configurations","text":"Option Default Description config.autoscaling.minReplicas 1 Defines the minimum number of replicas for HorizontalPodScaling config.autoscaling.maxReplicas 3 Defines the maximum number of replicas for HorizontalPodScaling config.autoscaling.targetCPUUtilizationPercentage 20 Defines the CPU threshold to trigger scaling config.autoscaling.targetMemoryUtilizationPercentage 50 Defines the RAM threshold to trigger scaling"},{"location":"helm/deployment/#service-configurations","title":"Service configurations","text":"Option Default Description config.service.type ClusterIP Defines the type of Kubernetes service config.service.port 80 Defines the port of Kubernetes service"},{"location":"helm/deployment/#ingress-configurations","title":"Ingress configurations","text":"Option Default Description config.ingress.enabled false Defines whether the Kubernetes Ingress resource should be activated or not config.ingress.domain znuny.domain.tld Defines the Ingress public domain config.ingress.annotations [\"kubernetes.io/ingress.class: nginx\"] Defines Ingress annotations config.ingress.tls.enabled true Defines whether TLS should be enabled on Ingress or not config.ingress.tls.annotations [\"cert-manager.io/cluster-issuer: letsencrypt-prod\"] Defines annotations for ingress TLS functionalities"},{"location":"helm/deployment/#volumes-configurations","title":"Volumes configurations","text":"Option Default Description config.persistentVolumeClaims [] Defines persistent volumes, their names, their mounting"},{"location":"helm/deployment/#pod-configurations","title":"Pod configurations","text":"Option Default Description config.podAnnotations [] Defines pod annotations"},{"location":"helm/deployment/#resources-configurations","title":"Resources configurations","text":"Option Default Description config.resources.limits.cpu 100m Defines the pod CPU limit resources config.resources.limits.memory 128Mi Defines the pod RAM limit resources config.resources.requests.cpu 100m Defines the pod CPU request resources config.resources.requests.memory 128Mi Defines the pod RAM request resources"},{"location":"helm/development/","title":"Development","text":""},{"location":"helm/development/#prerequisites","title":"Prerequisites","text":"<p>K3D is the tool choose to have a local kubernetes development cluster.  </p> <p>Install K3D with the next command :</p> <pre><code>curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash\n</code></pre> <p>Tips</p> <p>Refer to the documentation for other installation methods. Go to K3D documentation </p>"},{"location":"helm/development/#create-a-development-cluster","title":"Create a development cluster","text":"<p>Use the following kind of configuration file of k3d to deploy a cluster.</p> k3d/cluster.yaml<pre><code>apiVersion: k3d.io/v1alpha5\nkind: Simple\nmetadata:\nname: znuny-dev-cluster\nservers: 3\nagents: 3\nkubeAPI:\nhost: \"znuny.domain.tld\"\nhostIP: \"127.0.0.1\"\nhostPort: \"7777\"\nimage: rancher/k3s:v1.26.6-k3s1\ntoken: znunuySecretToken\nsubnet: \"172.30.0.0/16\"\nports:\n- port: 8080:80\nnodeFilters:\n- loadbalancer\noptions:\nk3d:\nwait: true\ntimeout: \"60s\"\ndisableLoadbalancer: false\ndisableImageVolume: false\ndisableRollback: false\nloadbalancer:\nconfigOverrides:\n- settings.workerConnections=2048\nk3s: # options passed on to K3s itself\nextraArgs: # additional arguments passed to the `k3s server|agent` command; same as `--k3s-arg`\n- arg: \"--tls-san=znuny.domain.tld\"\nnodeFilters:\n- server:*\nkubeconfig:\nupdateDefaultKubeconfig: true\nswitchCurrentContext: true\n</code></pre> <p>The default domain used by the development cluster is znuny-dev-cluster. Ensure to add it at the local name resolution in the file /etc/hosts :</p> /etc/hosts<pre><code>127.0.0.1 znuny.domain.tld\n</code></pre> <p>Create the cluster :</p> <pre><code>k3d cluster create -c ./k3d/cluster.yaml\n</code></pre> <p>Delete cluster :</p> <pre><code>k3d cluster delete znuny-dev-cluster\n</code></pre>"},{"location":"helm/development/#templating","title":"Templating","text":"<p>Create templates to check compliance of deployed resources from the project root :</p> <pre><code>helm template znuny ./helm\n</code></pre>"},{"location":"helm/overview/","title":"Overview","text":""},{"location":"helm/overview/#design","title":"Design","text":"<p>The Helm charters available are developed with the aim of providing a quick and easy way to deploy a production-ready instance of the Znuny application using the docker-znuny container image.</p>"},{"location":"helm/overview/#features","title":"Features","text":"<p>They currently only manage the deployment of the Znuny application, as well as the Kubernetes ecosystem required for a high-performance, robust production environment.</p> <p>Helm charters manage the following resources:</p> <ul> <li>ServiceAccount</li> <li>ConfigMap</li> <li>PersistentVolumeClaims</li> <li>Deployment</li> <li>HorizontalPodScaling</li> <li>Service</li> <li>Ingress</li> </ul>"},{"location":"roadmaps/v6.5.3-2/","title":"V6.5.3 2","text":""},{"location":"roadmaps/v6.5.3-2/#catch-app-logs-to-format-them-in-json","title":"Catch app logs to format them in JSON","text":"<ul> <li> - Catch all application logs</li> <li> - Format logs</li> <li> - Write logs in STDOUT</li> <li> - Write logs in a file</li> </ul>"},{"location":"roadmaps/v6.5.3-3/","title":"V6.5.3 3","text":""},{"location":"roadmaps/v6.5.3-3/#integrate-postgresql-to-databases-supported","title":"Integrate PostgreSQL to databases supported","text":"<ul> <li> - Test the docker compose integration</li> <li> - Test the scripts initialization</li> </ul>"},{"location":"roadmaps/v6.5.3-4/","title":"V6.5.3 4","text":""},{"location":"roadmaps/v6.5.3-4/#custom-plugins","title":"Custom plugins","text":"<ul> <li> - Understand the plugins working</li> <li> - Create a method to add custom plugins dynamically</li> <li> - Add the feature to the Helm charts</li> </ul>"},{"location":"roadmaps/v6.5.3-5/","title":"V6.5.3 5","text":""},{"location":"roadmaps/v6.5.3-5/#databases-migrations","title":"Databases migrations","text":"<ul> <li> - Get the dump file from an object storage</li> <li> - Get the dump file from an other database</li> <li> - Get the dump file from the local filesystem</li> <li> - Check the dump file integrity</li> <li> - Check the dump file to ensure the aren't issues about the databases</li> <li> - Inject the dump file into the application database<ul> <li> - Test to MariaDB</li> <li> - Test to PostgreSQL</li> </ul> </li> <li> - Use Kubernetes job to perform the migration :<ul> <li> - From an object storage</li> <li> - From a database</li> <li> - From the local filesystem</li> </ul> </li> </ul> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\nname: znuny-database-to-database-migration\nnamespace: &lt;namespace&gt;\nspec:\ntemplate:\nspec:\ncontainers:\n- name: my-container\nimage: my-image\nenv:\nenvFrom:\n- configMapRef:\nname: &lt;name of the configmap&gt;\ncommand: [\n\"sh\",\n\"-c\",\n\"zcli\",\n\"migration\", \"database\", \"pgsql\",\n\"-h\",\n\"host\",\n\"-p\",\n\"port\",\n\"-n\", \"name\",\n\"-u\",\n\"user\",\n\"-w\",\n\"password\"\n]\nrestartPolicy: Never\n</code></pre>"},{"location":"znuny/commands/","title":"Commands","text":"<p>Zcli is e simple command line interface built to manage the image of Znuny.</p>"},{"location":"znuny/commands/#usage","title":"Usage","text":"<p>Zcli can be used as following :</p> <ul> <li><code>zcli COMMAND</code></li> <li><code>zcli [COMMAND] --help | -h</code></li> <li><code>zcli --version | -v</code></li> </ul>"},{"location":"znuny/commands/#global-commands","title":"Global commands","text":"<p>The are many main commands which can be run :</p> <ul> <li><code>config</code>: Manage the configuration of znuny<ul> <li><code>apache</code>: Create virtualhosts</li> <li><code>crons</code>: Create all crons</li> <li><code>customers</code>: Create customers authentications</li> <li><code>database</code>: Initialize the database</li> <li><code>operators</code>: Create operators authentications</li> <li><code>znuny</code>: Create the main configuration file of Znuny</li> </ul> </li> <li><code>check</code>: Check some features or resources<ul> <li><code>modules</code>: Check Perl modules</li> <li><code>config</code>: Check the built configuration in database</li> </ul> </li> <li><code>download</code>: Download the znuny archive</li> <li><code>init</code>: Initialize the container</li> <li><code>run</code>: Run Znuny<ul> <li><code>cron</code>: Run the crons of Znuny</li> <li><code>daemon</code>: Run the daemon of Znuny</li> <li><code>znuny</code>: Run Znuny</li> </ul> </li> <li><code>user</code>: Manage users<ul> <li><code>admin</code>: Create the admin user</li> <li><code>permissions</code>: Set the user permissions</li> <li><code>system</code>: Create the system user</li> </ul> </li> </ul>"},{"location":"znuny/commands/#global-options","title":"Global options","text":"<ul> <li><code>--help</code> ou <code>-h</code>: Show this help</li> <li><code>--version</code> ou <code>-v</code>: Show version number</li> </ul>"},{"location":"znuny/commands/#environment-variables","title":"Environment variables","text":"<p>Zcli is designed to be as dynamic configurable as posible. All features supported can be set with environment variables.  </p> <p>Environement variables availables :</p> <ul> <li><code>ZNUNY_LOG_PATH</code>: The log file path</li> <li><code>ZNUNY_DATABASE_TYPE</code>: The database type (mysql, pgsql)</li> <li><code>ZNUNY_DATABASE_HOST</code>: The database host</li> <li><code>ZNUNY_DATABASE_NAME</code>: The database name</li> <li><code>ZNUNY_DATABASE_USER</code>: The database user</li> <li><code>ZNUNY_DATABASE_PASSWORD</code>: The database password</li> <li><code>ZNUNY_USER_ADMIN_NAME</code>: The admin user name</li> <li><code>ZNUNY_USER_ADMIN_PASSWORD</code>: The admin user password</li> <li><code>ZNUNY_MAILING_TYPE</code>: The mailing type</li> <li><code>ZNUNY_MAILING_HOST</code>: The mailing host</li> <li><code>ZNUNY_MAILING_PORT</code>: The mailing port</li> <li><code>ZNUNY_MAILING_USER</code>: The mailing user</li> <li><code>ZNUNY_MAILING_PASSWORD</code>: The mailing password</li> <li><code>ZNUNY_APACHE_DOMAIN</code>: The application domain</li> <li><code>ZNUNY_APACHE_REWRITE_RULES</code>: A custom rewrite rule</li> <li><code>ZNUNY_CUSTOMER_BACKEND_X</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_X</code>: Customers authentication synchronization</li> <li><code>ZNUNY_AGENTS_BACKEND_X</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_SYNCHRO_X</code>: Agents authentication synchronization</li> </ul> <p>Info</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p>"},{"location":"znuny/deployment/","title":"Deployment","text":""},{"location":"znuny/deployment/#required-configurations","title":"Required configurations","text":"<p>Not all features are active by default, and therefore don't necessarily need to be configured.</p> <p>Others, on the other hand, do require configuration during deployment.</p> <p>These features are as follows:</p> <ul> <li>Database configuration</li> </ul> <p>Example</p> <p>The most basic deployment should include an image and the environment variables for the database connection.</p> <p>If necessary, add configuration elements such as port forwarding, container name, hostname, etc.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n</code></pre> <p>Warning</p> <p>The <code>ZNUNY_DATABASE_TYPE</code> variable is extremely important, as it determines which database manager is used on the backend,  and therefore which type of client is used on the application side to connect to it. The variable must be set to <code>mysql</code> for a MariaDB or MySQL database, or <code>pgsql</code> for a PostgreSQL database.</p>"},{"location":"znuny/deployment/#optional-configurations","title":"Optional configurations","text":"<p>Deployment of the containerized application is fully configurable via environment variables.</p> <p>Each feature therefore has a variable capable of enabling or disabling it, and customizing its configuration.</p> MailsLogsApacheUserCustomersAgents docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_MAILING_TYPE: external\nZNUNY_MAILING_HOST: smpt.domain.tld\nZNUNY_MAILING_PORT: 25\nZNUNY_MAILING_USER: znuny\nZNUNY_MAILING_PASSWORD: password\n</code></pre> <p>Info</p> <p>To enable mail sending via an external server, the <code>ZNUNY_MAILING_TYPE</code> variable must be set to <code>external</code>. Otherwise, this variable will be set to <code>internal</code> and all other <code>ZNUNY_MAILING_XXX</code> mail configuration variables will be ignored when configuring the application.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_LOG_PATH: /var/log/znuny\n</code></pre> <p>Info</p> <p>By default, the Znuny application uses Rsyslog to manage its logging. However, with this method, the amount of logging is often low or non-existent. The <code>ZNUNY_LOG_PATH</code> variable allows you to dispense with Rsyslog for log management.  The application will simply write to a single log file, whose path can be customized.</p> <p>The Znuny application does not write all its activity in its log files. Only actions performed via the application's command line are logged. Daemon and cron logs are output directly in the standard json container output.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_APACHE_DOMAIN: znuny.domain.tld\nZNUNY_APACHE_REWRITE_RULES: |-\nRewriteRule ^/$ https://%{HTTP_HOST}/otrs/customer.pl\nRewriteRule ^/otrs/$ https://%{HTTP_HOST}/otrs/customer.pl\nRewriteRule ^/otrs$ https://%{HTTP_HOST}/otrs/customer.pl\n</code></pre> <p>Info</p> <p>If required, you can set up a web domain for the virtualhost of the Apache2 server. This can be especially useful if you want to have a record of it in the server logs. If no domain is specified, then the Apache2 server will be configured with a \"default\"  value for the virtualhost's ServerNmae option.</p> <p>If required, you can also configure request rewriting rules directly in the virtualhost configuration.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_USER_ADMIN_NAME: root@localhost\nZNUNY_USER_ADMIN_PASSWORD: password\n</code></pre> <p>Info</p> <p>Local administrator user configuration only works if LDAP agent configurations are not specified. If agent LDAP configurations are defined, those of the local administrator user become obsolete.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_CUSTOMER_BACKEND_1: |-\n$$Self-&gt;{AuthModule} = 'Kernel::System::Auth::LDAP';\n$$Self-&gt;{'AuthModule::LDAP::Host'} = 'ldap.example.com';\n$$Self-&gt;{'AuthModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n$$Self-&gt;{'AuthModule::LDAP::UID'} = 'uid';\n$$Self-&gt;{'AuthModule::LDAP::GroupDN'} = 'cn=znuny-allow,ou=posixGroups,dc=example,dc=com';\n$$Self-&gt;{'AuthModule::LDAP::AccessAttr'} = 'memberUid';\n$$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'UID';\n$$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'DN';\nZNUNY_CUSTOMER_SYNCHRO_1: |-\n$$Self-&gt;{'AuthSyncModule'} = 'Kernel::System::Auth::Sync::LDAP';\n$$Self-&gt;{'AuthSyncModule::LDAP::Host'} = 'ldap.example.com';\n$$Self-&gt;{'AuthSyncModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n$$Self-&gt;{'AuthSyncModule::LDAP::UID'} = 'uid';\n$$Self-&gt;{'AuthSyncModule::LDAP::SearchUserDN'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::SearchUserPw'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::AlwaysFilter'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::UserSyncMap'} = {\nUserFirstname =&gt; 'givenName',\nUserLastname  =&gt; 'sn',\nUserEmail     =&gt; 'mail',\n};\n</code></pre> <p>Info</p> <p>This step is almost mandatory to keep user management simple and efficient.</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\nznuny:\nimage: ghcr.io/mln-nicolas-b/docker-znuny:6.5.3-1\ncontainer_name: znuny\nhostname: znuny\nports:\n- 8080:80\nenvironment:\nZNUNY_DATABASE_TYPE: mysql\nZNUNY_DATABASE_HOST: mariadb\nZNUNY_DATABASE_PORT: 3306\nZNUNY_DATABASE_NAME: znuny\nZNUNY_DATABASE_USER: znuny\nZNUNY_DATABASE_PASSWORD: password\n\nZNUNY_AGENT_BACKEND_1: |-\n$$Self-&gt;{AuthModule} = 'Kernel::System::Auth::LDAP';\n$$Self-&gt;{'AuthModule::LDAP::Host'} = 'ldap.example.com';\n$$Self-&gt;{'AuthModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n$$Self-&gt;{'AuthModule::LDAP::UID'} = 'uid';\n$$Self-&gt;{'AuthModule::LDAP::GroupDN'} = 'cn=znuny-allow,ou=posixGroups,dc=example,dc=com';\n$$Self-&gt;{'AuthModule::LDAP::AccessAttr'} = 'memberUid';\n$$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'UID';\n$$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'DN';\nZNUNY_AGENT_SYNCHRO_1: |-\n$$Self-&gt;{'AuthSyncModule'} = 'Kernel::System::Auth::Sync::LDAP';\n$$Self-&gt;{'AuthSyncModule::LDAP::Host'} = 'ldap.example.com';\n$$Self-&gt;{'AuthSyncModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n$$Self-&gt;{'AuthSyncModule::LDAP::UID'} = 'uid';\n$$Self-&gt;{'AuthSyncModule::LDAP::SearchUserDN'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::SearchUserPw'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::AlwaysFilter'} = '';\n$$Self-&gt;{'AuthSyncModule::LDAP::UserSyncMap'} = {\nUserFirstname =&gt; 'givenName',\nUserLastname  =&gt; 'sn',\nUserEmail     =&gt; 'mail',\n};\n</code></pre> <p>Info</p> <p>This step is almost mandatory to keep operator management simple and efficient.</p> <p>LDAP configuration for agents disables local users.</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p>"},{"location":"znuny/development/","title":"Development","text":""},{"location":"znuny/development/#quick-start","title":"Quick start","text":"<p>The deployment of the development stack is managed with Docker Compose. The global configuration is splited in severals compose manifests which  are located in directory compose.  </p> <p>This method allows you to switch from one file to another to obtain the  desired technical stack.</p> <p>After editing the file docker-compose.yaml, just deploy the stack.</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"znuny/overview/","title":"Overview","text":"<p>The development of this container image for the Znuny application revolves around the use of a command-line tool.</p> <p>This command-line tool is called <code>zcli</code> and is a bash script developed with the bash framework named Bashly.</p> <p>The script <code>zcli</code> embeds all the tools required to manage the various functionalities supported.</p> <p>The entry point to the docker image is this single script.  </p>"}]}