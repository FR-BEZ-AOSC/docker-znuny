{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>This documentation is under development, as is the project it concerns. Some elements may be missing, superfluous, need to be modified or clarified.  </p> <p>In the event of problems or requests,  it is possible to open an issue :material-information-outline:{ title=\"As docker-znuny is a side project, little time is spent on it\" }</p>"},{"location":"#design","title":"Design","text":"<p>The aim of this project, centered on the znuny application, is to provide a reliable,  high-performance container image for quick and easy production release. </p> <p>This image and the various deployment methods provided in the repository are specifically  designed to be hosted on a Kubernetes platform.</p> <p>The various functionalities are designed for production use with a multitude of deployed instances.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Local users configuration</li> <li>Support for multiple databases<ul> <li>MariaDB</li> <li>PostgreSQL</li> </ul> </li> <li>Mailing configuration</li> <li>Ldap authentication configuration<ul> <li>Ldap agents authentication</li> <li>Ldap consumer authentication</li> </ul> </li> <li>Log outputs formatted in JSON and configurable between rsyslog and file outputs</li> <li>Configuration of Apache rewrite rules</li> </ul>"},{"location":"development/docker-znuny/","title":"Docker Znuny","text":""},{"location":"development/docker-znuny/#quick-start","title":"Quick start","text":"<p>The deployment of the development stack is managed with Docker Compose.  </p> <pre><code>---\nversion: \"3\"\n\nnetworks:\n  net:\n\nvolumes:\n  pgsql:\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: ./znuny/Dockerfile\n    image: ghcr.io/fr-bez-aosc/znuny:alpha-6.1.1\n    container_name: znuny\n    environment:\n      ZNUNY_DATABASE_TYPE: pgsql\n      ZNUNY_DATABASE_HOST: postgresql\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n    networks:\n      - net\n    ports:\n      - 8080:80\n    depends_on:\n      - db\n  db:\n    image: bitnami/postgresql:16\n    container_name: postgresql\n    environment:\n      PGDATA: /var/lib/postgresql/data/pgdata\n      POSTGRES_DB: znuny\n      POSTGRES_USER: znuny\n      POSTGRES_PASSWORD: password\n    volumes:\n      - pgsql:/var/lib/postgresql/data/pgdata\n    networks:\n      - net\n    ports:\n      - 8080:80\n</code></pre> <p>After editing the file docker-compose.yaml, just deploy the stack.</p> <pre><code>docker-compose up\n</code></pre>"},{"location":"development/helm-charts/","title":"Helm Charts","text":""},{"location":"development/helm-charts/#prerequisites","title":"Prerequisites","text":"<p>K3D is the tool choose to have a local kubernetes development cluster.  </p> <p>Install K3D with the next command :</p> <pre><code>curl -s https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash\n</code></pre> <p>Tips</p> <p>Refer to the documentation for other installation methods. Go to K3D documentation </p>"},{"location":"development/helm-charts/#create-a-development-cluster","title":"Create a development cluster","text":"<p>Use the following kind of configuration file of k3d to deploy a cluster.</p> k3d/cluster.yaml <p>The default domain used by the development cluster is znuny-dev-cluster. Ensure to add it at the local name resolution in the file /etc/hosts :</p> /etc/hosts<pre><code>127.0.0.1 znuny.domain.tld\n</code></pre> <p>Create the cluster :</p> <pre><code>k3d cluster create -c ./k3d/cluster.yaml\n</code></pre> <p>Delete cluster :</p> <pre><code>k3d cluster delete znuny-dev-cluster\n</code></pre>"},{"location":"development/helm-charts/#templating","title":"Templating","text":"<p>Create templates to check compliance of deployed resources from the project root :</p> <pre><code>helm template znuny ./helm\n</code></pre>"},{"location":"docker-znuny/v6.1.1/commands/","title":"Commands","text":"<p>Zcli is e simple command line interface built to manage the image of Znuny.</p>"},{"location":"docker-znuny/v6.1.1/commands/#usage","title":"Usage","text":"<p>Zcli can be used as following :</p> <ul> <li><code>zcli COMMAND</code></li> <li><code>zcli [COMMAND] --help | -h</code></li> <li><code>zcli --version | -v</code></li> </ul>"},{"location":"docker-znuny/v6.1.1/commands/#global-commands","title":"Global commands","text":"<p>The are many main commands which can be run :</p> <ul> <li><code>config</code>: Manage the configuration of znuny<ul> <li><code>apache</code>: Create virtualhosts</li> <li><code>crons</code>: Create all crons</li> <li><code>customers</code>: Create customers authentications</li> <li><code>database</code>: Initialize the database</li> <li><code>operators</code>: Create operators authentications</li> <li><code>znuny</code>: Create the main configuration file of Znuny</li> </ul> </li> <li><code>check</code>: Check some features or resources<ul> <li><code>modules</code>: Check Perl modules</li> <li><code>config</code>: Check the built configuration in database</li> </ul> </li> <li><code>download</code>: Download the znuny archive</li> <li><code>init</code>: Initialize the container</li> <li><code>run</code>: Run Znuny<ul> <li><code>cron</code>: Run the crons of Znuny</li> <li><code>daemon</code>: Run the daemon of Znuny</li> <li><code>znuny</code>: Run Znuny</li> </ul> </li> <li><code>user</code>: Manage users<ul> <li><code>admin</code>: Create the admin user</li> <li><code>permissions</code>: Set the user permissions</li> <li><code>system</code>: Create the system user</li> </ul> </li> <li><code>job</code>: Commands for kubernetes job<ul> <li><code>upgrade</code>: Upgrade database schemas</li> <li><code>migration</code>: Migrate an existing database from a PostgreSQL server to the application database</li> </ul> </li> <li><code>shell</code>: Commands for TTY shell<ul> <li><code>upgrade</code>: Upgrade database schemas</li> </ul> </li> </ul>"},{"location":"docker-znuny/v6.1.1/commands/#global-options","title":"Global options","text":"<ul> <li><code>--help</code> ou <code>-h</code>: Show this help</li> <li><code>--version</code> ou <code>-v</code>: Show version number</li> </ul>"},{"location":"docker-znuny/v6.1.1/commands/#environment-variables","title":"Environment variables","text":"<p>Zcli is designed to be as dynamic configurable as posible. All features supported can be set with environment variables.  </p> <p>Environement variables availables :</p> <ul> <li><code>ZNUNY_LOG_PATH</code>: The log file path</li> <li><code>ZNUNY_DATABASE_HOST</code>: The database host</li> <li><code>ZNUNY_DATABASE_NAME</code>: The database name</li> <li><code>ZNUNY_DATABASE_USER</code>: The database user</li> <li><code>ZNUNY_DATABASE_PASSWORD</code>: The database password</li> <li><code>ZNUNY_USER_ADMIN_NAME</code>: The admin user name</li> <li><code>ZNUNY_USER_ADMIN_PASSWORD</code>: The admin user password</li> <li><code>ZNUNY_MAILING_TYPE</code>: The mailing type</li> <li><code>ZNUNY_MAILING_HOST</code>: The mailing host</li> <li><code>ZNUNY_MAILING_PORT</code>: The mailing port</li> <li><code>ZNUNY_MAILING_USER</code>: The mailing user</li> <li><code>ZNUNY_MAILING_PASSWORD</code>: The mailing password</li> <li><code>ZNUNY_APACHE_DOMAIN</code>: The application domain</li> <li><code>ZNUNY_APACHE_REWRITE_RULES</code>: A custom rewrite rule</li> <li><code>ZNUNY_CUSTOMER_BACKEND_X</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_X</code>: Customers authentication synchronization</li> <li><code>ZNUNY_AGENTS_BACKEND_X</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_SYNCHRO_X</code>: Agents authentication synchronization</li> </ul> <p>Info</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p>"},{"location":"docker-znuny/v6.1.1/deployment/","title":"Deployment","text":""},{"location":"docker-znuny/v6.1.1/deployment/#required-configurations","title":"Required configurations","text":"<p>Not all features are active by default, and therefore don't necessarily need to be configured.</p> <p>Others, on the other hand, do require configuration during deployment.</p> <p>These features are as follows:</p> <ul> <li>Database configuration</li> </ul> <p>Example</p> <p>The most basic deployment should include an image and the environment variables for the database connection.</p> <p>If necessary, add configuration elements such as port forwarding, container name, hostname, etc.</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n      - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n</code></pre>"},{"location":"docker-znuny/v6.1.1/deployment/#optional-configurations","title":"Optional configurations","text":"<p>Deployment of the containerized application is fully configurable via environment variables.</p> <p>Each feature therefore has a variable capable of enabling or disabling it, and customizing its configuration.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#mails","title":"Mails","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_MAILING_TYPE: external\n      ZNUNY_MAILING_HOST: smpt.domain.tld\n      ZNUNY_MAILING_PORT: 25\n      ZNUNY_MAILING_USER: znuny\n      ZNUNY_MAILING_PASSWORD: password\n</code></pre> <p>Info</p> <p>To enable mail sending via an external server, the <code>ZNUNY_MAILING_TYPE</code> variable must be set to <code>external</code>. Otherwise, this variable will be set to <code>internal</code> and all other mail configuration variables will be ignored when the application will be configured.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#logs","title":"Logs","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_LOG_PATH: /var/log/znuny\n</code></pre> <p>Info</p> <p>By default, the application Znuny uses Rsyslog to manage its logging. However, with this method, the amount of logging is often low or non-existent. The variable <code>ZNUNY_LOG_PATH</code> allows you to dispense with Rsyslog for log management.  The application will simply write to a single log file, whose path can be customized.</p> <p>The Znuny application does not write all its activity in its log files. Only actions performed via the application's command line are logged. Daemon and cron logs are output directly in the standard json container output.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#apache","title":"Apache","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_APACHE_DOMAIN: znuny.domain.tld\n      ZNUNY_APACHE_REWRITE_RULES: |-\n        RewriteRule ^/$ https://%{HTTP_HOST}/otrs/customer.pl\n        RewriteRule ^/otrs/$ https://%{HTTP_HOST}/otrs/customer.pl\n        RewriteRule ^/otrs$ https://%{HTTP_HOST}/otrs/customer.pl\n</code></pre> <p>Info</p> <p>If required, you can set up a web domain for the virtualhost of the Apache2 server. This can be especially useful if you want to have a record of it in the server logs. If no domain is specified, then the Apache2 server will be configured with a \"default\"  value for the virtualhost's ServerNmae option.</p> <p>If required, you can also configure request rewriting rules directly in the virtualhost configuration.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#user","title":"User","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_USER_ADMIN_NAME: root@localhost\n      ZNUNY_USER_ADMIN_PASSWORD: password\n</code></pre> <p>Info</p> <p>Local administrator user configuration only works if LDAP agent configurations are not specified. If agent LDAP configurations are defined, those of the local administrator user become obsolete.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#customers","title":"Customers","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_CUSTOMER_BACKEND_1: |-\n        $$Self-&gt;{AuthModule} = 'Kernel::System::Auth::LDAP';\n        $$Self-&gt;{'AuthModule::LDAP::Host'} = 'ldap.example.com';\n        $$Self-&gt;{'AuthModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n        $$Self-&gt;{'AuthModule::LDAP::UID'} = 'uid';\n        $$Self-&gt;{'AuthModule::LDAP::GroupDN'} = 'cn=znuny-allow,ou=posixGroups,dc=example,dc=com';\n        $$Self-&gt;{'AuthModule::LDAP::AccessAttr'} = 'memberUid';\n        $$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'UID';\n        $$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'DN';\n      ZNUNY_CUSTOMER_SYNCHRO_1: |-\n        $$Self-&gt;{'AuthSyncModule'} = 'Kernel::System::Auth::Sync::LDAP';\n        $$Self-&gt;{'AuthSyncModule::LDAP::Host'} = 'ldap.example.com';\n        $$Self-&gt;{'AuthSyncModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n        $$Self-&gt;{'AuthSyncModule::LDAP::UID'} = 'uid';\n        $$Self-&gt;{'AuthSyncModule::LDAP::SearchUserDN'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::SearchUserPw'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::AlwaysFilter'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::UserSyncMap'} = {\n            UserFirstname =&gt; 'givenName',\n            UserLastname  =&gt; 'sn',\n            UserEmail     =&gt; 'mail',\n        };\n</code></pre> <p>Info</p> <p>This step is almost mandatory to keep user management simple and efficient.</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p>"},{"location":"docker-znuny/v6.1.1/deployment/#agents","title":"Agents","text":"<p>Example</p> docker-compose.yaml<pre><code>---\nversion: \"3\"\n\nservices:\n  app:\n    image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n    container_name: znuny\n    ports:\n    - 8080:80\n    environment:\n      ZNUNY_DATABASE_HOST: db\n      ZNUNY_DATABASE_PORT: 5432\n      ZNUNY_DATABASE_NAME: znuny\n      ZNUNY_DATABASE_USER: znuny\n      ZNUNY_DATABASE_PASSWORD: password\n      ZNUNY_AGENT_BACKEND_1: |-\n        $$Self-&gt;{AuthModule} = 'Kernel::System::Auth::LDAP';\n        $$Self-&gt;{'AuthModule::LDAP::Host'} = 'ldap.example.com';\n        $$Self-&gt;{'AuthModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n        $$Self-&gt;{'AuthModule::LDAP::UID'} = 'uid';\n        $$Self-&gt;{'AuthModule::LDAP::GroupDN'} = 'cn=znuny-allow,ou=posixGroups,dc=example,dc=com';\n        $$Self-&gt;{'AuthModule::LDAP::AccessAttr'} = 'memberUid';\n        $$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'UID';\n        $$Self-&gt;{'AuthModule::LDAP::UserAttr'} = 'DN';\n      ZNUNY_AGENT_SYNCHRO_1: |-\n        $$Self-&gt;{'AuthSyncModule'} = 'Kernel::System::Auth::Sync::LDAP';\n        $$Self-&gt;{'AuthSyncModule::LDAP::Host'} = 'ldap.example.com';\n        $$Self-&gt;{'AuthSyncModule::LDAP::BaseDN'} = 'dc=example,dc=com';\n        $$Self-&gt;{'AuthSyncModule::LDAP::UID'} = 'uid';\n        $$Self-&gt;{'AuthSyncModule::LDAP::SearchUserDN'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::SearchUserPw'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::AlwaysFilter'} = '';\n        $$Self-&gt;{'AuthSyncModule::LDAP::UserSyncMap'} = {\n            UserFirstname =&gt; 'givenName',\n            UserLastname  =&gt; 'sn',\n            UserEmail     =&gt; 'mail',\n        };\n</code></pre> <p>Info</p> <p>This step is almost mandatory to keep operator management simple and efficient.</p> <p>LDAP configuration for agents disables local users.</p> <p>Environment variables ending in <code>_X</code> are repeatable variables and are therefore suffixed with a number. The <code>X</code> character must be replaced by a number between 1 and 9, allowing multiple LDAP connection backends to be configured.</p> <p>Use of any other number will be ignored.</p>"},{"location":"docker-znuny/v6.1.1/environment/","title":"Environment","text":"<p>Environment Variables:</p> <ul> <li><code>ZNUNY_LOG_PATH</code>: The log file path</li> <li><code>ZNUNY_DATABASE_HOST</code>: The database host</li> <li><code>ZNUNY_DATABASE_NAME</code>: The database name</li> <li><code>ZNUNY_DATABASE_USER</code>: The database user</li> <li><code>ZNUNY_DATABASE_PASSWORD</code>: The database password</li> <li><code>ZNUNY_USER_ADMIN_NAME</code>: The admin user name</li> <li><code>ZNUNY_USER_ADMIN_PASSWORD</code>: The admin user password</li> <li><code>ZNUNY_MAILING_TYPE</code>: The mailing type</li> <li><code>ZNUNY_MAILING_HOST</code>: The mailing host</li> <li><code>ZNUNY_MAILING_PORT</code>: The mailing port</li> <li><code>ZNUNY_MAILING_USER</code>: The mailing user</li> <li><code>ZNUNY_MAILING_PASSWORD</code>: The mailing password</li> <li><code>ZNUNY_APACHE_DOMAIN</code>: The application domain</li> <li><code>ZNUNY_APACHE_REWRITE_RULES</code>: A custom rewrite rule</li> <li><code>ZNUNY_CUSTOMER_BACKEND_1</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_2</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_3</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_4</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_5</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_6</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_7</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_8</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_BACKEND_9</code>: Customers authentication backend</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_1</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_2</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_3</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_4</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_5</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_6</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_7</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_8</code>: Customers authentication synchronization</li> <li><code>ZNUNY_CUSTOMER_SYNCHRO_9</code>: Customers authentication synchronization</li> <li><code>ZNUNY_AGENTS_BACKEND_1</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_2</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_3</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_4</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_5</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_6</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_7</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_8</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_BACKEND_9</code>: Agents authentication backend</li> <li><code>ZNUNY_AGENTS_SYNCHRO_1</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_2</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_3</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_4</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_5</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_6</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_7</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_8</code>: Agents authentication synchronization</li> <li><code>ZNUNY_AGENTS_SYNCHRO_9</code>: Agents authentication synchronization</li> </ul>"},{"location":"helm-charts/v0.1.1/installation/","title":"Installation","text":""},{"location":"helm-charts/v0.1.1/installation/#posgressql","title":"PosgresSQL","text":"<p>Our Helm package does not manage the database, so it must be installed before Znuny is deployed. Nous recommandons d'utiliser l'image PostgreSQL de fourie et maintenue par Bitnami.</p> <p>Add Bitnami's Helm repository :</p> <pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre> <p>Create the custom values file \"./values.postgresql.yaml\" using the following as an example :</p> <pre><code>image:\n  registry: docker.io\n  repository: bitnami/postgresql\n  tag: 16\n  pullPolicy: IfNotPresent\n\nauth:\n  enablePostgresUser: false\n  postgresPassword: \"password\"\n  username: \"znuny\"\n  password: \"password\"\n  database: \"znuny\"\n\nprimary:\n  resources:\n    requests:\n      cpu: 1\n      memory: 512Mi\n    limits:\n      cpu: 2\n      memory: 1024Mi\n  persistence:\n    enabled: true\n    storageClass: \"\"\n    size: 10Gi\n    accessModes:\n      - ReadWriteOnce\n</code></pre> <p>Install the Helm release :</p> <pre><code>helm upgrade --install postgresql bitnami/postgresql \\\n  --namespace demo \\\n  --values ./values.postgresql.yaml\n</code></pre> <p>We assume the namespace already exists</p> <p>Once the deployment is complete, a few operations must be performed to allow Znuny to deploy correctly. if the PostgreSQL administrator user's password is not known, retrieve it as follows :</p> <pre><code>export POSTGRES_ADMIN_PASSWORD=$(kubectl get secret --namespace testcharts postgresql -o jsonpath=\"{.data.postgres-password}\" | base64 -d)\n</code></pre> <p>Then elevate the privileges of the user used by the application to ensure error-free deployment of Znuny :</p> <pre><code>kubectl run postgresql-client \\\n  --rm -tty --stdin \\ \n  --restart='Never' \\\n  --namespace demo \\\n  --image docker.io/bitnami/postgresql:16 \\\n  --env=\"PGPASSWORD=$POSTGRES_ADMIN_PASSWORD\" \\\n  --command -- psql \\\n    --host postgresql \\\n    -U postgres \\\n    -d znuny \\\n    -p 5432 \\\n    -c \"ALTER ROLE znuny WITH SUPERUSER;\"\n</code></pre> <p>The name of the role to act on depends on the value of auth.username value used when deploying PostgreSQL</p>"},{"location":"helm-charts/v0.1.1/installation/#znuny","title":"Znuny","text":"<p>Add Eviden's Helm repository :</p> <pre><code>helm repo add aosc https://helm-charts.aosc-portal.com\n</code></pre> <p>Create the custom values file \"./values.znuny.yaml\" using the following as an example :</p> <pre><code>replicaCount: 1\n\nimage:\n  repository: ghcr.io/fr-bez-aosc/znuny\n  tag: beta-6.1.1\n  pullPolicy: IfNotPresent\n\nconfig:\n  database:\n    host: postgresql.demo.svc.cluster.local\n    port: 5432\n    name: znuny\n    user: znuny\n    password: password\n</code></pre> <p>Install the Helm release :</p> <pre><code>helm install znuny aosc/znuny \\\n  --namespace demo \\\n  --version 0.1.1\n  --values ./values.znuny.yaml\n</code></pre>"},{"location":"helm-charts/v0.1.1/migration/","title":"Migration","text":""},{"location":"helm-charts/v0.1.1/migration/#migrate-an-existing-instance-on-a-new-one","title":"Migrate an existing instance on a new one","text":"<p>Create the job manifest file \"./job.migration.yaml\" using the following as an example :</p> <pre><code>---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: znuny-migration-db2db\nspec:\n  template:\n    spec:\n      containers:\n        - name: zcli\n          image: ghcr.io/fr-bez-aosc/znuny:&lt;tag&gt;\n          envFrom:\n          - configMapRef:\n              name: znuny-config\n          - secretRef:\n              name: znuny-secrets\n          command:\n            - \"/usr/bin/zcli\"\n            - \"job\"\n            - \"migration\"\n            - \"database\"\n            - \"-h\"\n            - \"postgresql.default.svc.cluster.local\"    # The kubernetes domain of the remote database\n            - \"-p\"\n            - \"5432\"                                    # The port exposed by the kubernetes service\n            - \"-n\"\n            - \"znuny\"                                   # The name of the remote database\n            - \"-u\"\n            - \"znuny\"                                   # The user used for the remote connection\n            - \"-w\"\n            - \"password\"                                # The user's password used for the remote connection\n      restartPolicy: Never\n</code></pre> <p>Make sure the image used is the same version as the target deployment.</p> <p>Stop the new instance :</p> <pre><code>kubectl patch deployment znuny \\\n  -n demo \\\n  -p '{\"spec\": {\"replicas\": 0}}'\n</code></pre> <p>Migrate migrate the database :</p> <pre><code>kubectl create \\\n  -n demo \\\n  -f ./tests/job.migration.yaml\n</code></pre> <p>Restart the new instance :</p> <pre><code>kubectl patch deployment znuny \\\n  -n demo \\\n  -p '{\"spec\": {\"replicas\": 1}}'\n</code></pre> <p>If desired, delete the migration job :</p> <pre><code>kubectl delete \\\n  -n demo \\\n  -f ./tests/job.migration.yaml\n</code></pre>"},{"location":"helm-charts/v0.1.1/parameters/","title":"Parameters","text":""},{"location":"helm-charts/v0.1.1/parameters/#helm-release-configurations","title":"Helm release configurations","text":"Option Default Description nameOverride {} Overrides the release name namespaceOverride {} Overrides the namespace name"},{"location":"helm-charts/v0.1.1/parameters/#serviceaccount-configurations","title":"ServiceAccount configurations","text":"Option Default Description serviceAccount.create true Defines whether the ServiceAccount should be created or not serviceAccount.annotations {} Defines ServiceAccount annotations serviceAccount.name \"\" Defines the name of the ServiceAccount"},{"location":"helm-charts/v0.1.1/parameters/#pod-strategies-configurations","title":"Pod strategies configurations","text":"Option Default Description imagePullSecrets [] Defines the secrets to be used to pull the image restartPolicy Always Defines the restart policy deploymentStrategy Recreate Defines the deployment behavour replicaCount 1 Define the desired number of replicas"},{"location":"helm-charts/v0.1.1/parameters/#image-configurations","title":"Image configurations","text":"Option Default Description image.repository ghcr.io/mln-nicolas-b/docker-znuny Defines the name of the image to be used image.tag v6.5.3-1 Defines the tag of the image to be used image.pullPolicy IfNotPresent Defines the pull policy of the image"},{"location":"helm-charts/v0.1.1/parameters/#logs-configurations","title":"Logs configurations","text":"Option Default Description config.logs {} Defines whether the Znuny application should log to a file and provides the file path."},{"location":"helm-charts/v0.1.1/parameters/#external-database-configurations","title":"External database configurations","text":"Option Default Description config.database.type mysql Defines the type of the external database config.database.host host Defines the host of the external database config.database.port port Defines the port of the external database config.database.name name Defines the name of the external database config.database.user user Defines the connection user of the external database config.database.password password Defines the connection password of the external database"},{"location":"helm-charts/v0.1.1/parameters/#web-server-configurations","title":"Web server configurations","text":"Option Default Description config.apache.domain znuny.domain.tld Defines a ServerName in the virtualhost of the Apache2 server config.apache.rewriteRules {} Defines request rewriting rules in the Apache2 server virtualhost"},{"location":"helm-charts/v0.1.1/parameters/#local-users-configurations","title":"Local users configurations","text":"Option Default Description config.users.admin.name root@localhost Defines the username of the local administrator user config.users.admin.password password Defines the password of the local administrator user"},{"location":"helm-charts/v0.1.1/parameters/#mailing-configurations","title":"Mailing configurations","text":"Option Default Description config.mails.type external Defines the method used to send e-mails config.mails.host smtp.domain.tld Defines the SMTP server host config.mails.port 25 Defines the SMTP server port config.mails.user znuny@domain.tld Defines the SMTP server user name config.mails.password none Defines the SMTP server user password"},{"location":"helm-charts/v0.1.1/parameters/#authentications-backends-configurations","title":"Authentications backends configurations","text":"Option Default Description config.authentications.customers.backends {} Define an authentication backend for customer login config.authentications.customers.synchronizations {} Defines a synchronization backend for local client storage config.authentications.agents.backends {} Define an authentication backend for agent login config.authentications.agents.synchronizations {} Defines a synchronization backend for local client storage"},{"location":"helm-charts/v0.1.1/parameters/#autoscaling-configurations","title":"Autoscaling configurations","text":"Option Default Description config.autoscaling.minReplicas 1 Defines the minimum number of replicas for HorizontalPodScaling config.autoscaling.maxReplicas 3 Defines the maximum number of replicas for HorizontalPodScaling config.autoscaling.targetCPUUtilizationPercentage 20 Defines the CPU threshold to trigger scaling config.autoscaling.targetMemoryUtilizationPercentage 50 Defines the RAM threshold to trigger scaling"},{"location":"helm-charts/v0.1.1/parameters/#service-configurations","title":"Service configurations","text":"Option Default Description config.service.type ClusterIP Defines the type of Kubernetes service config.service.port 80 Defines the port of Kubernetes service"},{"location":"helm-charts/v0.1.1/parameters/#ingress-configurations","title":"Ingress configurations","text":"Option Default Description config.ingress.enabled false Defines whether the Kubernetes Ingress resource should be activated or not config.ingress.domain znuny.domain.tld Defines the Ingress public domain config.ingress.annotations [\"kubernetes.io/ingress.class: nginx\"] Defines Ingress annotations config.ingress.tls.enabled true Defines whether TLS should be enabled on Ingress or not config.ingress.tls.annotations [\"cert-manager.io/cluster-issuer: letsencrypt-prod\"] Defines annotations for ingress TLS functionalities"},{"location":"helm-charts/v0.1.1/parameters/#volumes-configurations","title":"Volumes configurations","text":"Option Default Description config.persistentVolumeClaims [] Defines persistent volumes, their names, their mounting"},{"location":"helm-charts/v0.1.1/parameters/#pod-configurations","title":"Pod configurations","text":"Option Default Description config.podAnnotations [] Defines pod annotations"},{"location":"helm-charts/v0.1.1/parameters/#resources-configurations","title":"Resources configurations","text":"Option Default Description config.resources.limits.cpu 100m Defines the pod CPU limit resources config.resources.limits.memory 128Mi Defines the pod RAM limit resources config.resources.requests.cpu 100m Defines the pod CPU request resources config.resources.requests.memory 128Mi Defines the pod RAM request resources"},{"location":"helm-charts/v0.1.1/upgrade/","title":"Upgrade","text":"<p>Znuny must be at least in version 6.0.x</p>"},{"location":"helm-charts/v0.1.1/upgrade/#upgrade-the-depoyment","title":"Upgrade the depoyment","text":"<p>To upgrade Znuny's deployment, simply deploy a new charts version :</p> <pre><code>helm upgrade znuny aosc/znuny \\\n  --namespace aosc \\\n  --version 0.1.1 \\\n  --reuse-values\n</code></pre> <p>If needed, set the image tag to deploy a specific container image :</p> <pre><code>helm upgrade znuny aosc/znuny \\\n  --namespace aosc \\\n  --version 0.1.1 \\\n  --set image.tag=&lt;tag&gt; \\\n  --reuse-values\n</code></pre>"},{"location":"helm-charts/v0.1.1/upgrade/#upgrade-the-database-schemas","title":"Upgrade the database schemas","text":"<p>Create the job manifest file \"./job.upgrade.yaml\" using the following as an example :</p> <pre><code>---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: znuny-upgrade-6.1.1\nspec:\n  template:\n    spec:\n      containers:\n        - name: zcli\n          image: ghcr.io/fr-bez-aosc/znuny:beta-6.1.1\n          envFrom:\n          - configMapRef:\n              name: znuny-config\n          - secretRef:\n              name: znuny-secrets\n          command:\n            - \"/usr/bin/zcli\"\n            - \"job\"\n            - \"upgrade\"\n      restartPolicy: Never\n</code></pre> <p>Make sure the image used is the same version as the target deployment.</p> <p>Stop the instance :</p> <pre><code>kubectl patch deployment znuny \\\n  -n demo \\\n  -p '{\"spec\": {\"replicas\": 0}}'\n</code></pre> <p>Upgrade database schemas :</p> <pre><code>kubectl create \\\n  -n demo \\\n  -f ./tests/job.upgrade.yaml\n</code></pre> <p>Restart the instance :</p> <pre><code>kubectl patch deployment znuny \\\n  -n demo \\\n  -p '{\"spec\": {\"replicas\": 1}}'\n</code></pre> <p>If desired, delete the upgrade job :</p> <pre><code>kubectl delete \\\n  -n demo \\\n  -f ./tests/job.upgrade.yaml\n</code></pre>"},{"location":"overviews/docker-znuny/","title":"Docker Znuny","text":"<p>The development of this container image for the Znuny application revolves around the use of a command-line tool.</p> <p>This command-line tool is called <code>zcli</code> and is a bash script developed with the bash framework named Bashly.</p> <p>The script <code>zcli</code> embeds all the tools required to manage the various functionalities supported.</p> <p>The entry point to the docker image is this single script.  </p>"},{"location":"overviews/helm-charts/","title":"Helm Charts","text":""},{"location":"overviews/helm-charts/#design","title":"Design","text":"<p>The Helm charters available are developed with the aim of providing a quick and easy way to deploy a production-ready instance of the Znuny application using the docker-znuny container image.</p>"},{"location":"overviews/helm-charts/#features","title":"Features","text":"<p>They currently only manage the deployment of the Znuny application, as well as the Kubernetes ecosystem required for a high-performance, robust production environment.</p> <p>Helm charters manage the following resources:</p> <ul> <li>ServiceAccount</li> <li>ConfigMap</li> <li>PersistentVolumeClaims</li> <li>Deployment</li> <li>HorizontalPodScaling</li> <li>Service</li> <li>Ingress</li> </ul>"}]}